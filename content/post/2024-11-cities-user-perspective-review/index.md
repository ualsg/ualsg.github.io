---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "New paper: Understanding the user perspective on urban public spaces"
subtitle: "Cities publishes our new systematic review with a focus on opportunities for machine learning."
summary: "Cities publishes our new systematic review with a focus on opportunities for machine learning."
authors: [admin]
tags: [paper, computer vision, machine learning, urban design, public spaces]
categories: []
date: 2024-11-07T13:58:22+08:00
lastmod: 2024-11-07T13:58:22+08:00
featured: false
draft: false
show_related: true
pager: true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.

---

We are glad to share our new paper:

> Zhu Y, Zhang Y, Biljecki F (2025): Understanding the user perspective on urban public spaces: A systematic review and opportunities for machine learning. Cities, 156: 105535. [<i class="ai ai-doi-square ai"></i> 10.1016/j.cities.2024.105535](https://doi.org/10.1016/j.cities.2024.105535) [<i class="far fa-file-pdf"></i> PDF](/publication/2025-cities-userperspective/2025-cities-userperspective.pdf)</i> <i class="ai ai-open-access-square ai"></i>

This research was led by {{% mention "yihan" %}}.
Congratulations on his new publication that is part of his PhD! :raised_hands: :clap:

The paper is available open access.

![](1.png)


### Highlights


+ Studies on user's perspective of urban public spaces are at the infant stage.
+ Researchers study the user's perspective on urban public spaces from ten dimensions.
+ Perception interpretation, user demographics and data acquisition are key challenges.
+ Machine learning offers significant potential for addressing the above challenges.

![](2.png)


### Abstract

> With people-centered approaches gaining prominence in urban development, studying urban public spaces from the user's perspective has become crucial for effective urban design, planning, and policy-making. The rapid advancement of Machine Learning (ML) techniques has enhanced the ability to analyze and understand user data in urban public spaces, such as usage patterns, activities, and public opinions. However, limited efforts have been made on a structured understanding of urban public spaces from the user's perspective. These knowledge gaps have also hindered the full realization of ML's potential in describing and analyzing urban public spaces. After systematically reviewing 319 relevant papers, this study analyzes ten dimensions of the user's perspective on urban public spaces and identifies three unaddressed issues: (1) interpretation of user's perception, (2) overlooked user demographics, and (3) data acquisition. In addition, this review also examines the applications of ML to these dimensions and their potential to tackle the three issues, and highlights two main opportunities to integrate ML for more rigorous and data-driven public spaces studies: (1) combining Computer Vision and Natural Language Processing in public spaces quality measurement and (2) investing in high-quality user data.

![](3.png)

### Paper 

For more information, please see the [paper](/publication/2025-cities-userperspective/) (open access <i class="ai ai-open-access-square ai"></i>).

[![](page-one.png)](/publication/2025-cities-userperspective/)

BibTeX citation:
```bibtex
@article{2025_cities_userperspective,
  author = {Yihan Zhu and Ye Zhang and Filip Biljecki},
  doi = {10.1016/j.cities.2024.105535},
  journal = {Cities},
  pages = {105535},
  title = {Understanding the user perspective on urban public spaces: A systematic review and opportunities for machine learning},
  volume = {156},
  year = {2025}
}
```
